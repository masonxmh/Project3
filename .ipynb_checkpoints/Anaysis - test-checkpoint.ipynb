{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Data download\n",
    "\n",
    "All these data is from https://data.mendeley.com/datasets/rscbjbr9sj/3, and uploaded to AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import split_folders\n",
    "\n",
    "# ! pip install keras==2.3.0\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, BatchNormalization\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/chest_xray'):\n",
    "    os.makedirs('./data', exist_ok=True)\n",
    "    urllib.request.urlretrieve(\"https://project3-data.s3.amazonaws.com/chest_xray.zip\", \"data/chest_xray.zip\")\n",
    "    with ZipFile('data/chest_xray.zip', 'r') as zipObj:\n",
    "# Extract all the contents of zip file in current directory\n",
    "        zipObj.extractall(path='data/')\n",
    "# Remove zip file\n",
    "    os.remove('data/chest_xray.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Retrieving the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/chest_xray/'\n",
    "\n",
    "n_normal = len(os.listdir(path + '/NORMAL'))\n",
    "n_pneumonia = len(os.listdir(path + '/PNEUMONIA'))\n",
    "print('normal images:'+ str(n_normal))\n",
    "print('Pneumonia images:'+ str(n_pneumonia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels for the sections of our pie chart\n",
    "labels = [\"Normal\", \"Pneumonia\"]\n",
    "# The values of each section of the pie chart\n",
    "sizes = [n_normal, n_pneumonia]\n",
    "# Tells matplotlib to seperate the \"Python\" section from the others\n",
    "explode = (0.1, 0)\n",
    "\n",
    "# Creates the pie chart based upon the values above\n",
    "# Automatically finds the percentages of each part of the pie chart\n",
    "plt.pie(sizes, explode=explode, labels=labels,\n",
    "        autopct=\"%1.1f%%\", shadow=True, startangle=140)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_img = plt.imread(path+'/NORMAL/'+os.listdir(path+'/NORMAL')[0])\n",
    "pneu_img = plt.imread(path+'/PNEUMONIA/'+os.listdir(path+'/PNEUMONIA')[0])\n",
    "\n",
    "plt.subplot(1,2,1).set_title('NORMAL')\n",
    "plt.imshow(norm_img, cmap='gray')\n",
    "\n",
    "plt.subplot(1,2,2).set_title('PNEUMONIA')\n",
    "plt.imshow(pneu_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Data Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Input Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "split_folders.ratio('data/chest_xray', output=\"data/output\", seed=1337, ratio=(.8, .1, .1)) # default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of our datasets\n",
    "output_path = 'data/output/'\n",
    "subdirectory_names = []\n",
    "subdirectory_file_counts = []\n",
    "for _set in ['train', 'val', 'test']:\n",
    "    n_normal = len(os.listdir(output_path + _set + '/NORMAL'))\n",
    "    n_infect = len(os.listdir(output_path + _set + '/PNEUMONIA'))\n",
    "    print('Set: {}, normal images: {}, pneumonia images: {}'.format(_set, n_normal, n_infect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subdir_file_count(master_dir):\n",
    "    subdirs = os.listdir(master_dir)\n",
    "    subdir_count = len(subdirs)\n",
    "\n",
    "    subdir_names = []\n",
    "    subdir_file_counts = []\n",
    "\n",
    "    for subdir in subdirs:\n",
    "        dir = os.path.join(master_dir, subdir)\n",
    "        file_count = len(os.listdir(dir))\n",
    "        subdir_names.append(subdir)\n",
    "        subdir_file_counts.append(file_count)\n",
    "    \n",
    "    return subdir_names, subdir_file_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/output/train'\n",
    "val_dir = 'data/output/val'\n",
    "test_dir = 'data/output/test'\n",
    "\n",
    "\n",
    "plt.figsize=(12,4)\n",
    "subdir_file_count(train_dir)\n",
    "plt.subplot(1,3,1).set_title('Training')\n",
    "dir_name, dir_file_count = subdir_file_count(train_dir)\n",
    "x = [i for i in dir_name]\n",
    "y = dir_file_count\n",
    "sns.barplot(x=x, y=y)\n",
    "\n",
    "plt.subplot(1,3,2).set_title('Validation')\n",
    "dir_name, dir_file_count = subdir_file_count(val_dir)\n",
    "x = [i for i in dir_name]\n",
    "y = dir_file_count\n",
    "sns.barplot(x=x, y=y)\n",
    "\n",
    "plt.subplot(1,3,3).set_title('Test')\n",
    "dir_name, dir_file_count = subdir_file_count(test_dir)\n",
    "x = [i for i in dir_name]\n",
    "y = dir_file_count\n",
    "sns.barplot(x=x, y=y)\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the normal and pneumonia sub-directories\n",
    "normal_cases_dir = train_dir + '/NORMAL'\n",
    "pneumonia_cases_dir = train_dir + '/PNEUMONIA' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data into Keras Model\n",
    "![Test Image 1](image/generator_structure.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.3, # default value: 0.2\n",
    "        vertical_flip=True) # default value: horizontal_flip=True\n",
    "\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Train Generator\n",
    "* The directory must be set to the path where your ‘n’ classes of folders are present.\n",
    "* The target_size is the size of your input images, every image will be resized to this size.\n",
    "* color_mode: if the image is either black and white or grayscale set “grayscale” or if the image has three color channels, set “rgb”.\n",
    "* batch_size: No. of images to be yielded from the generator per batch.\n",
    "* class_mode: Set “binary” if you have only two classes to predict, if not set to“categorical”, in case if you’re developing an Autoencoder system, both input and the output would probably be the same image, for this case set to “input”.\n",
    "* shuffle: Set True if you want to shuffle the order of the image that is being yielded, else set False.\n",
    "* seed: Random seed for applying random image augmentation and shuffling the order of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "img_dims = 150\n",
    "batch_size = 32\n",
    "class_mode = \"categorical\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_dims, img_dims),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode= class_mode,\n",
    "        shuffle=True,\n",
    "        seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Validation Generator\n",
    "* Same as train generator settings except for obvious changes like directory path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_dims, img_dims),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode= class_mode,\n",
    "        shuffle=True,\n",
    "        seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Test Generator\n",
    "* directory: path where there exists a folder, under which all the test images are present. For example, in this case, the images are found in data/output/test/\n",
    "* batch_size: Set this to some number that divides your total number of images in your test set exactly.\n",
    "  Why this only for test_generator?\n",
    "  Actually, you should set the “batch_size” in both train and valid generators to some number that divides your total number of images in your train set and valid respectively, but this doesn’t matter before because even if batch_size doesn’t match the number of samples in the train or valid sets and some images gets missed out every time we yield the images from generator, it would be sampled the very next epoch you train.\n",
    "  But for the test set, you should sample the images exactly once, no less or no more. If Confusing, just set it to 1(but maybe a little bit slower).\n",
    "* class_mode: Set this to None, to return only the images.\n",
    "* shuffle: Set this to False, because you need to yield the images in “order”, to predict the outputs and match them with their unique ids or filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory= test_dir,\n",
    "    target_size=(img_dims, img_dims),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode= None,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight =  class_weight.compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 Building a model\n",
    "\n",
    "\n",
    "Convolutional Neural Network (CNN, or ConvNet) seems to be obvious choice given recent achievements in image classification leveraging deep learning.\n",
    "\n",
    "Since training of large neural networks takes immense amounts of computational power (not to mention time) we decide to use transfer learning. This concept boils down to reusing parts of the already trained networks in one domain to classify images in another domain. I our case we decided to use network trained on generic images from ImageNet database and tune it to detect pneumonia.\n",
    "\n",
    "We leverage one of the most basic pre-trained networks called VGG16 \n",
    "![Test Image 2](image/vgg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define Outputlayer\n",
    "When loading a given model, the “include_top” argument can be set to False, in which case the fully-connected output layers of the model used to make predictions is not loaded, allowing a new output layer to be added and trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reduce number of trained parameters we will block first 20 layers of the model (up to the Flatten phase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[0:20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for idx, layer in enumerate(model.layers):\n",
    "        print(\"layer {}: {}, trainable: {}\".format(idx, layer.name, layer.trainable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the \"cross-entropy\" loss function, which works well for learning probability distributions for classification.\n",
    "\n",
    "See e.g.: https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complie the model\n",
    "#RMSprop()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',     \n",
    "              optimizer=optimizer, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "model_path = \"output/model/\"\n",
    "log_path = \"output/TensorBoardLog/\"\n",
    "# + time.strftime('%Y-%m-%d %H-%M-%S') + \"/\"\n",
    "# + time.strftime('%Y-%m-%d %H-%M-%S')\n",
    "model_dir = model_path \n",
    "log_dir = log_path \n",
    "\n",
    "model_file = model_dir + \"{epoch:02d}-val_acc-{val_accuracy:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "checkPoint = ModelCheckpoint(\n",
    "    model_file,\n",
    "    monitor=\"val_acc\",\n",
    "    verbose=0,\n",
    "    save_best_only=True\n",
    "#     mode=\"auto\"\n",
    ")\n",
    "\n",
    "stopPoint = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "#     mode=\"auto\",\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.1,\n",
    "    patience=5,\n",
    "    min_lr=0.0001,\n",
    "    cooldown=2\n",
    ")\n",
    "\n",
    "# tensorboard = TensorBoard(\n",
    "#     log_dir=log_dir,\n",
    "#     write_graph=True,\n",
    "#     update_freq=\"batch\"\n",
    "# )\n",
    "\n",
    "callback = [checkPoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting/Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "        epochs=50,\n",
    "        verbose=1,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=STEP_SIZE_VALID,\n",
    "        callbacks=callback,\n",
    "        class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify our Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss, model_accuracy = model.evaluate_generator(\n",
    "    generator=validation_generator,\n",
    "    steps=STEP_SIZE_VALID,\n",
    "    verbose=1)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Visualization over the Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "plt.figure(figsize=(16,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "# summarize history for loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('output/model_image/model_0.94_0.04_Adam.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"model/model_0.94_0.04_Adam.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = keras.models.load_model(\"model/model_0.94_0.15_Adam.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "# summarize history for loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('output/model_image/model_0.94_0.04_Adam.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify our Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss, model_accuracy = model.evaluate_generator(\n",
    "    generator=validation_generator,\n",
    "    steps=STEP_SIZE_VALID,\n",
    "    verbose=1)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "STEP_SIZE_TEST=test_generator.n\n",
    "y_pred=model.predict(test_generator, steps=STEP_SIZE_TEST, verbose=1)\n",
    "y_pred_label = y_pred.argmax(axis=1)\n",
    "y_true_label=test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_true_label, y_pred_label) \n",
    "recall = recall_score(y_true_label, y_pred_label) \n",
    "f1 = f1_score(y_true_label, y_pred_label)\n",
    "\n",
    "print(\"-\"*40)\n",
    "print(\"Derived Report\")\n",
    "print(\"-\"*40)\n",
    "print(\"%s%.3f%s\"% (\"Precision     : \", precision*100, \"%\"))\n",
    "print(\"%s%.3f%s\"% (\"Recall        : \", recall*100,    \"%\"))\n",
    "print(\"%s%.3f%s\"% (\"F1-Score      : \", f1*100,        \"%\"))\n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "CM = confusion_matrix(y_true_label, y_pred_label)\n",
    "\n",
    "fig, ax = plot_confusion_matrix(CM ,  figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\n",
    "plt.xticks(range(2), ['Normal', 'Pneumonia'] , fontsize=16)\n",
    "plt.yticks(range(2), ['Normal', 'Pneumonia'] , fontsize=16)\n",
    "plt.title(\"Confusion Matrix for Model File (Test Dataset): \\n\"+\"model_title\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report = classification_report(y_true_label, y_pred_label, target_names=['Normal', 'Pneumonia'])\n",
    "\n",
    "print(\"-\"*55)\n",
    "print(\"Report for Model File: \")\n",
    "print(\"-\"*55)\n",
    "print(class_report)\n",
    "print(\"-\"*55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_generator.reset()\n",
    "# STEP_SIZE_TEST=test_generator.n\n",
    "# y_pred=model.predict(test_generator, steps=STEP_SIZE_TEST, verbose=1)\n",
    "# y_pred_label = y_pred.argmax(axis=1)\n",
    "# y_true_label=test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numofbatch = test_generator.n\n",
    "batch_no = random.randint(0, numofbatch-1)\n",
    "\n",
    "y_img_batch, y_true_batch = test_generator[batch_no]\n",
    "\n",
    "y_pred_batch = model.predict(y_img_batch)\n",
    "y_pred_batch = y_pred_batch.argmax(axis=-1)\n",
    "\n",
    "sizeofbatch = len(y_true_batch)\n",
    "print(\"-\"*35)\n",
    "print(\"%s%d\"%     (\"Selected Batch No       : \", batch_no))\n",
    "print(\"-\"*35)\n",
    "print(\"%s%d\"%     (\"Batch Size              : \", len(y_pred_batch)))\n",
    "print(\"-\"*35)\n",
    "print(\"%s%.2f%s\"% (\"Accuracy                : \", np.mean(y_true==y_pred)*100, \"%\"))\n",
    "print(\"-\"*35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
